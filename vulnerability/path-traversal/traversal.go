package sqli

import (
	"net/http"

	"github.com/gen2brain/go-unarr"
	"github.com/julienschmidt/httprouter"
)

type PathTraversal struct{}

func New() PathTraversal {
	return PathTraversal{}
}

func (PathTraversal) SetRouter(r *httprouter.Router) {
	r.GET("/path-traversal", pathTraversalHandler)
}

const (
	// Extraction limits to prevent resource exhaustion
	maxFileSize       = 10 * 1024 * 1024 // 10MB per file
	maxTotalSize      = 100 * 1024 * 1024 // 100MB total extraction
	maxFiles          = 1000 // Maximum number of files
	maxExtractionTime = 30 * time.Second // 30 seconds timeout
	maxArchiveDepth   = 5 // Maximum depth for nested archives
)

// validateFilePath checks if a file path is safe (no path traversal)
func validateFilePath(filePath string) bool {
	// Handle URL encoding by decoding potential encoded sequences
	decodedPath := filePath
	// Replace URL encoded path traversal attempts (%2e%2e/ => ../)
	decodedPath = strings.ReplaceAll(decodedPath, "%2e", ".")
	decodedPath = strings.ReplaceAll(decodedPath, "%2E", ".")
	
	// Normalize Unicode to prevent Unicode normalization attacks
	normalizedPath := filePath
	if !utf8.ValidString(normalizedPath) {
		return false
	}
	
	// Normalize the path
	cleanPath := filepath.Clean(decodedPath)
	
	// Check for path traversal attempts
	if strings.Contains(cleanPath, "..") || 
	   strings.HasPrefix(cleanPath, "/") || 
	   strings.HasPrefix(cleanPath, "\\") ||
	   strings.Contains(cleanPath, ":") { // Prevent Windows drive references
		return false
	}
	
	// Additional checks for common evasion techniques
	if strings.Contains(filePath, "\u0000") { // Null byte injection
		return false
	}
	
	return true
}

// validateArchiveFormat checks if the provided data is a valid archive
func validateArchiveFormat(data io.Reader) (bool, []byte, error) {
	// Read a header portion for content type detection
	headerBytes, err := ioutil.ReadAll(io.LimitReader(data, 262)) // Read only enough for type detection
	if err != nil {
		return false, nil, err
	}
	
	// Check if the file is a valid archive type
	kind, _ := filetype.Match(headerBytes)
	if kind == filetype.Unknown {
		return false, nil, fmt.Errorf("unknown file type")
	}
	
	// List of allowed archive types
	allowedTypes := []string{
		"application/zip",
		"application/x-rar-compressed", 
		"application/gzip",
		"application/x-tar",
	}
	
	// Verify content type is an allowed archive format
	valid := false
	for _, allowed := range allowedTypes {
		if kind.MIME.Value == allowed {
			valid = true
			break
		}
	}
	
	return valid, headerBytes, nil
}

// createIsolatedDirectory creates a per-request temporary directory
func createIsolatedDirectory() (string, error) {
	// Create unique directory name using UUID to prevent path guessing
	uniqueID := uuid.New().String()
	tempDir := filepath.Join(os.TempDir(), "extract-"+uniqueID)
	
	// Create directory with restricted permissions (only owner can access)
	err := os.MkdirAll(tempDir, 0700)
	if err != nil {
		return "", err
	}
	
	return tempDir, nil
}

// safeExtract extracts archive contents safely after validating file paths
func safeExtract(archive *unarr.Archive, destDir string) error {
	fileCount := 0
	totalSize := int64(0)
	extractedFiles := make(map[string]bool)
	
	// Create a context with timeout to prevent long-running extractions
	ctx, cancel := context.WithTimeout(context.Background(), maxExtractionTime)
	defer cancel()
	
	done := make(chan error, 1)
	go func() {
		for archive.Next() {
			// Check if timeout has occurred
			select {
			case <-ctx.Done():
				done <- fmt.Errorf("extraction timeout after %v", maxExtractionTime)
				return
			default:
				// Continue processing
			}
			
			entry, err := archive.Entry()
			if err != nil {
				done <- err
				return
			}
			
			// Log the file being processed
			log.Printf("Processing archive entry: %s (size: %d bytes)", entry.Name, entry.Size)
			
			// Check file size to prevent zip bombs
			if entry.Size > int64(maxFileSize) {
				done <- fmt.Errorf("file too large: %s (%d bytes)", entry.Name, entry.Size)
				return
			}
			
			// Track total extraction size
			totalSize += entry.Size
			if totalSize > int64(maxTotalSize) {
				done <- fmt.Errorf("total extraction size exceeds limit (%d bytes)", maxTotalSize)
				return
			}
			
			// Track number of files
			fileCount++
			if fileCount > maxFiles {
				done <- fmt.Errorf("too many files in archive (max: %d)", maxFiles)
				return
			}
			
			// Validate the file path to prevent directory traversal
			if !validateFilePath(entry.Name) {
				done <- fmt.Errorf("invalid path detected: %s", entry.Name)
				return
			}
			
			// Check for duplicate filenames which could indicate overwrite attempts
			if extractedFiles[entry.Name] {
				done <- fmt.Errorf("duplicate file name detected: %s", entry.Name)
				return
			}
			extractedFiles[entry.Name] = true
		}
		
		// After validation of all entries, perform the actual extraction
		files, err := archive.Extract(destDir)
		if err != nil {
			done <- err
			return
		}
		
		// Set proper permissions on all extracted files
		for _, file := range files {
			fullPath := filepath.Join(destDir, file)
			// Set files to read-only for owner, no permissions for others
			err = os.Chmod(fullPath, 0400)
			if err != nil {
				done <- fmt.Errorf("failed to set permissions on %s: %v", file, err)
				return
			}
			
			// Validate file type after extraction if it's not a directory
			if info, err := os.Stat(fullPath); err == nil && !info.IsDir() {
				// Check file content type for extra security
				if err := validateExtractedFileType(fullPath); err != nil {
					done <- err
					return
				}
			}
		}
		
		done <- nil
	}()
	
	// Wait for extraction to complete or timeout
	select {
	case err := <-done:
		return err
	case <-ctx.Done():
		return fmt.Errorf("extraction timeout after %v", maxExtractionTime)
	}
}

// validateExtractedFileType performs additional validation on extracted files
func validateExtractedFileType(filePath string) error {
	file, err := os.Open(filePath)
	if err != nil {
		return err
	}
	defer file.Close()
	
	// Read file header for type detection
	header := make([]byte, 261)
	if _, err := file.Read(header); err != nil && err != io.EOF {
		return err
	}
	
	// Detect file type
	kind, _ := filetype.Match(header)
	
	// Block potentially dangerous file types
	dangerousTypes := []string{
		"application/x-executable", 
		"application/x-sharedlib",
		"application/x-dosexec", // Windows executables
	}
	
	for _, dangerous := range dangerousTypes {
		if kind.MIME.Value == dangerous {
			return fmt.Errorf("dangerous file type detected in %s: %s", filePath, kind.MIME.Value)
		}
	}
	
	return nil
}

func pathTraversalHandler(w http.ResponseWriter, r *http.Request, _ httprouter.Params) {
	// Log the extraction request
	log.Printf("Received archive extraction request from %s", r.RemoteAddr)
	
	// Validate content type
	contentType := r.Header.Get("Content-Type")
	if !strings.HasPrefix(contentType, "multipart/form-data") && 
	   contentType != "application/zip" && 
	   contentType != "application/x-rar-compressed" && 
	   contentType != "application/gzip" {
		log.Printf("Invalid content type: %s", contentType)
		http.Error(w, "Invalid content type, must be an archive format", http.StatusBadRequest)
		return
	}
	
	// Limit the request body size to prevent resource exhaustion
	r.Body = http.MaxBytesReader(w, r.Body, int64(maxTotalSize))
	
	// Validate archive format
	isValid, headerBytes, err := validateArchiveFormat(r.Body)
	if err != nil || !isValid {
		log.Printf("Invalid archive format: %v", err)
		http.Error(w, "Invalid archive format", http.StatusBadRequest)
		return
	}
	
	// Create a temporary file with the header bytes plus the remaining body
	tempFile, err := ioutil.TempFile("", "archive-*")
	if err != nil {
		log.Printf("Failed to create temporary file: %v", err)
		http.Error(w, "Internal server error", http.StatusInternalServerError)
		return
	}
	defer os.Remove(tempFile.Name())
	defer tempFile.Close()
	
	// Write the header bytes
	if _, err := tempFile.Write(headerBytes); err != nil {
		log.Printf("Failed to write to temporary file: %v", err)
		http.Error(w, "Internal server error", http.StatusInternalServerError)
		return
	}
	
	// Copy the rest of the body
	if _, err := io.Copy(tempFile, r.Body); err != nil {
		log.Printf("Failed to read request body: %v", err)
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}
	
	// Seek back to start of file
	if _, err := tempFile.Seek(0, 0); err != nil {
		log.Printf("Failed to seek in temporary file: %v", err)
		http.Error(w, "Internal server error", http.StatusInternalServerError)
		return
	}
	
	// Create archive from the temporary file
	a, err := unarr.NewArchive(tempFile.Name())
	if err != nil {
		log.Printf("Failed to process archive: %v", err)
		http.Error(w, "Failed to process archive", http.StatusBadRequest)
		return
	}
	defer a.Close()
	
	// Create isolated directory for extraction
	extractDir, err := createIsolatedDirectory()
	if err != nil {
		log.Printf("Failed to create isolated directory: %v", err)
		http.Error(w, "Internal server error", http.StatusInternalServerError)
		return
	}
	
	// Schedule cleanup of the temporary directory
	defer func() {
		log.Printf("Cleaning up extraction directory: %s", extractDir)
		os.RemoveAll(extractDir)
	}()
	
	// Use safe extraction method that validates paths
	err = safeExtract(a, extractDir)
	if err != nil {
		log.Printf("Extraction failed: %v", err)
		http.Error(w, "Failed to extract archive safely: "+err.Error(), http.StatusBadRequest)
		return
	}
	
	log.Printf("Archive extracted successfully to %s", extractDir)
	w.Write([]byte("Archive extracted successfully"))
}

